module {
  func.func @"torch-jit-export"(%arg0: !torch.vtensor<[?,?,16,64],f32>) -> !torch.vtensor<[?,?,1024],f32> attributes {torch.onnx_meta.ir_version = 7 : si64, torch.onnx_meta.opset_version = 21 : si64, torch.onnx_meta.producer_name = "pytorch", torch.onnx_meta.producer_version = "1.11.0"} {
    %0 = torch.aten._shape_as_tensor %arg0 : !torch.vtensor<[?,?,16,64],f32> -> !torch.vtensor<[4],si64>
    %1 = torch.vtensor.literal(dense<0> : tensor<si64>) : !torch.vtensor<[],si64>
    %int0 = torch.constant.int 0
    %int0_0 = torch.constant.int 0
    %int1 = torch.constant.int 1
    %2 = torch.aten.lt.Scalar %1, %int0_0 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[],i1>
    %3 = torch.aten.size.int %0, %int0 : !torch.vtensor<[4],si64>, !torch.int -> !torch.int
    %4 = torch.aten.add.Scalar %1, %3, %int1 : !torch.vtensor<[],si64>, !torch.int, !torch.int -> !torch.vtensor<[],si64>
    %5 = torch.aten.where.self %2, %4, %1 : !torch.vtensor<[],i1>, !torch.vtensor<[],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[],si64>
    %6 = torch.prim.ListConstruct  : () -> !torch.list<int>
    %7 = torch.aten.unsqueeze %5, %int0_0 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[1],si64>
    %8 = torch.aten.index_select %0, %int0, %7 : !torch.vtensor<[4],si64>, !torch.int, !torch.vtensor<[1],si64> -> !torch.vtensor<[1],si64>
    %9 = torch.aten.squeeze.dim %8, %int0 : !torch.vtensor<[1],si64>, !torch.int -> !torch.vtensor<[],si64>
    %10 = torch.aten._shape_as_tensor %arg0 : !torch.vtensor<[?,?,16,64],f32> -> !torch.vtensor<[4],si64>
    %11 = torch.vtensor.literal(dense<1> : tensor<si64>) : !torch.vtensor<[],si64>
    %int0_1 = torch.constant.int 0
    %int0_2 = torch.constant.int 0
    %int1_3 = torch.constant.int 1
    %12 = torch.aten.lt.Scalar %11, %int0_2 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[],i1>
    %13 = torch.aten.size.int %10, %int0_1 : !torch.vtensor<[4],si64>, !torch.int -> !torch.int
    %14 = torch.aten.add.Scalar %11, %13, %int1_3 : !torch.vtensor<[],si64>, !torch.int, !torch.int -> !torch.vtensor<[],si64>
    %15 = torch.aten.where.self %12, %14, %11 : !torch.vtensor<[],i1>, !torch.vtensor<[],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[],si64>
    %16 = torch.prim.ListConstruct  : () -> !torch.list<int>
    %17 = torch.aten.unsqueeze %15, %int0_2 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[1],si64>
    %18 = torch.aten.index_select %10, %int0_1, %17 : !torch.vtensor<[4],si64>, !torch.int, !torch.vtensor<[1],si64> -> !torch.vtensor<[1],si64>
    %19 = torch.aten.squeeze.dim %18, %int0_1 : !torch.vtensor<[1],si64>, !torch.int -> !torch.vtensor<[],si64>
    %20 = torch.vtensor.literal(dense<0> : tensor<1xsi64>) : !torch.vtensor<[1],si64>
    %int0_4 = torch.constant.int 0
    %21 = torch.aten.unsqueeze %9, %int0_4 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[1],si64>
    %22 = torch.vtensor.literal(dense<0> : tensor<1xsi64>) : !torch.vtensor<[1],si64>
    %int0_5 = torch.constant.int 0
    %23 = torch.aten.unsqueeze %19, %int0_5 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[1],si64>
    %24 = torch.vtensor.literal(dense<1024> : tensor<1xsi64>) : !torch.vtensor<[1],si64>
    %25 = torch.prim.ListConstruct %21, %23, %24 : (!torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.list<vtensor>
    %int0_6 = torch.constant.int 0
    %26 = torch.aten.cat %25, %int0_6 : !torch.list<vtensor>, !torch.int -> !torch.vtensor<[3],si64>
    %int0_7 = torch.constant.int 0
    %int0_8 = torch.constant.int 0
    %27 = torch.aten.select.int %26, %int0_7, %int0_8 : !torch.vtensor<[3],si64>, !torch.int, !torch.int -> !torch.vtensor<[1],si64>
    %28 = torch.aten.item %27 : !torch.vtensor<[1],si64> -> !torch.int
    %29 = torch.aten.eq.int %28, %int0_7 : !torch.int, !torch.int -> !torch.bool
    %30 = torch.aten.Int.bool %29 : !torch.bool -> !torch.int
    %int0_9 = torch.constant.int 0
    %31 = torch.aten.size.int %arg0, %int0_9 : !torch.vtensor<[?,?,16,64],f32>, !torch.int -> !torch.int
    %32 = torch.prim.NumToTensor.Scalar %30 : !torch.int -> !torch.vtensor<[],i1>
    %33 = torch.prim.NumToTensor.Scalar %31 : !torch.int -> !torch.vtensor<[],si64>
    %34 = torch.prim.NumToTensor.Scalar %28 : !torch.int -> !torch.vtensor<[],si64>
    %35 = torch.aten.where.self %32, %33, %34 : !torch.vtensor<[],i1>, !torch.vtensor<[],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[],si64>
    %36 = torch.aten.item %35 : !torch.vtensor<[],si64> -> !torch.int
    %int1_10 = torch.constant.int 1
    %37 = torch.aten.select.int %26, %int0_7, %int1_10 : !torch.vtensor<[3],si64>, !torch.int, !torch.int -> !torch.vtensor<[1],si64>
    %38 = torch.aten.item %37 : !torch.vtensor<[1],si64> -> !torch.int
    %39 = torch.aten.eq.int %38, %int0_7 : !torch.int, !torch.int -> !torch.bool
    %40 = torch.aten.Int.bool %39 : !torch.bool -> !torch.int
    %int1_11 = torch.constant.int 1
    %41 = torch.aten.size.int %arg0, %int1_11 : !torch.vtensor<[?,?,16,64],f32>, !torch.int -> !torch.int
    %42 = torch.prim.NumToTensor.Scalar %40 : !torch.int -> !torch.vtensor<[],i1>
    %43 = torch.prim.NumToTensor.Scalar %41 : !torch.int -> !torch.vtensor<[],si64>
    %44 = torch.prim.NumToTensor.Scalar %38 : !torch.int -> !torch.vtensor<[],si64>
    %45 = torch.aten.where.self %42, %43, %44 : !torch.vtensor<[],i1>, !torch.vtensor<[],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[],si64>
    %46 = torch.aten.item %45 : !torch.vtensor<[],si64> -> !torch.int
    %int2 = torch.constant.int 2
    %47 = torch.aten.select.int %26, %int0_7, %int2 : !torch.vtensor<[3],si64>, !torch.int, !torch.int -> !torch.vtensor<[1],si64>
    %48 = torch.aten.item %47 : !torch.vtensor<[1],si64> -> !torch.int
    %49 = torch.aten.eq.int %48, %int0_7 : !torch.int, !torch.int -> !torch.bool
    %50 = torch.aten.Int.bool %49 : !torch.bool -> !torch.int
    %int2_12 = torch.constant.int 2
    %51 = torch.aten.size.int %arg0, %int2_12 : !torch.vtensor<[?,?,16,64],f32>, !torch.int -> !torch.int
    %52 = torch.prim.NumToTensor.Scalar %50 : !torch.int -> !torch.vtensor<[],i1>
    %53 = torch.prim.NumToTensor.Scalar %51 : !torch.int -> !torch.vtensor<[],si64>
    %54 = torch.prim.NumToTensor.Scalar %48 : !torch.int -> !torch.vtensor<[],si64>
    %55 = torch.aten.where.self %52, %53, %54 : !torch.vtensor<[],i1>, !torch.vtensor<[],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[],si64>
    %56 = torch.aten.item %55 : !torch.vtensor<[],si64> -> !torch.int
    %57 = torch.prim.ListConstruct %36, %46, %56 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %58 = torch.aten.reshape %arg0, %57 : !torch.vtensor<[?,?,16,64],f32>, !torch.list<int> -> !torch.vtensor<[?,?,1024],f32>
    return %58 : !torch.vtensor<[?,?,1024],f32>
  }
}

